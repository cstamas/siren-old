<?xml version="1.0" encoding="UTF-8" ?>
<!--
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<!--  
 This is the Solr schema file. This file should be named "schema.xml" and
 should be in the conf directory under the solr home
 (i.e. ./solr/conf/schema.xml by default) 
 or located where the classloader for the Solr webapp can find it.

 This example schema is the recommended starting point for users.
 It should be kept correct and concise, usable out-of-the-box.

 For more information, on how to customize this file, please see
 http://wiki.apache.org/solr/SchemaXml

 PERFORMANCE NOTE: this schema includes many optional features and should not
 be used for benchmarking.  To improve performance one could
  - set stored="false" for all fields possible (esp large fields) when you
    only need to search on the field but don't need to return the original
    value.
  - set indexed="false" if you don't need to search on the field, but only
    return the field as a result of searching on other indexed fields.
  - remove all unneeded copyField statements
  - for best index size and searching performance, set "index" to false
    for all general text fields, use copyField to copy them to the
    catchall "text" field, and use that for searching.
  - For maximum indexing performance, use the StreamingUpdateSolrServer
    java client.
  - Remember to run the JVM in server mode, and use a higher logging level
    that avoids logging every request
-->

<schema name="example" version="1.3">

  <types>

    <!-- The StrField type is not analyzed, but indexed/stored verbatim. -->
    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>

    <!-- A Trie based date field for faster date range queries and date faceting. -->
    <fieldType name="tdate" class="solr.TrieDateField" omitNorms="true" precisionStep="6" positionIncrementGap="0"/>

    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
        so that a query of "wifi" or "wi fi" could match a document containing 
				"Wi-Fi" or "WiFi".
        Stopwords is customized by external files. Stemming is disabled.
    -->
    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">

        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
      
        <!-- Splits words into subwords based on delimiters
             - split subwords based on case change
             - preserveOriginal="1" in order to preserve the original word.
             Removed split based on numerics to fix SND-355 and SND-1283 
        -->
        <filter class="solr.WordDelimiterFilterFactory" 
                generateWordParts="1" 
                generateNumberParts="1" 
                catenateWords="0" 
                catenateNumbers="0" 
                catenateAll="0" 
                splitOnCaseChange="1"
                splitOnNumerics="0"
                preserveOriginal="1"/>
        
        <!-- Filters out those tokens *not* having length min through max 
             inclusive. -->
        <filter class="solr.LengthFilterFactory" min="2" max="256"/>
        
        <!-- Change to lowercase text -->
        <filter class="solr.LowerCaseFilterFactory"/>
        
        <!-- Case insensitive stop word removal.
          add enablePositionIncrements=true in both the index and query
          analyzers to leave a 'gap' for more accurate phrase queries.
        -->
        <filter class="solr.StopFilterFactory"
                ignoreCase="true"
                words="stopwords.txt"
                enablePositionIncrements="true"
                />
        
      </analyzer>
      <analyzer type="query">
        <!-- UAX29URLEmailTokenizer for query in order to recognise URI, 
             email, and QName.
        -->
        <tokenizer class="solr.UAX29URLEmailTokenizerFactory"/>
                
        <!-- Filters out those tokens *not* having length min through max 
             inclusive. -->
        <filter class="solr.LengthFilterFactory" min="2" max="256"/>
        
        <filter class="solr.LowerCaseFilterFactory"/>
        
        <filter class="solr.StopFilterFactory"
                ignoreCase="true"
                words="stopwords.txt"
                enablePositionIncrements="true"
                />
                
        <!-- Replace Qnames by their name spaces in URIs. -->
        <filter class="org.sindice.siren.solr.analysis.QNamesFilterFactory" 
                qnames="qnames.txt"/>
				
      </analyzer>
    </fieldType>

    <!--
		  The SIREn NTriple field type:
			Use the TupleAnalyzer 
			- Parse n-triple data 
			- Tokenise Literals but also URIs
			
			Field norms are not useful for SIREn fields. Set omitNorms to true reduces
			memory consumption, and improve ranking.
		-->
    <fieldType name="ntriple" class="solr.TextField" omitNorms="true">
      <analyzer type="index">

        <tokenizer class="org.sindice.siren.solr.analysis.TupleTokenizerFactory"
				           subschema="ntriple-schema.xml"
									 literal-fieldtype="ntriple-literal"/>
				
        <!-- Token removal. By default, filter bnode, dot, datatype and language
				     tag token.
						 Add bnode=0 to not filter blank node tokens. -->
        <filter class="org.sindice.siren.solr.analysis.TokenTypeFilterFactory"/>
				
				<filter class="solr.StandardFilterFactory"/>
				
				<!-- Extract and tokenise localname of URIs.
				     Add maxLength=n to not tokenise localname with more than n 
						 characters. By default, maxLength=64. -->
				<filter class="org.sindice.siren.solr.analysis.URILocalnameFilterFactory"/>

        <!-- Remove trailing slash of URIs. -->				
				<filter class="org.sindice.siren.solr.analysis.URITrailingSlashFilterFactory"/>
        
        <!-- Change to lowercase text -->
        <filter class="solr.LowerCaseFilterFactory"/>
				
        <!-- Case insensitive stop word removal.
          add enablePositionIncrements=true in both the index and query
          analyzers to leave a 'gap' for more accurate phrase queries. -->
        <filter class="solr.StopFilterFactory"
                ignoreCase="true"
                words="stopwords.txt"
                enablePositionIncrements="true"
                />
				
				<!-- Filters out those tokens *not* having length min through max 
				     inclusive. -->
				<filter class="solr.LengthFilterFactory" min="2" max="256"/>
				
				<!-- Filter converting tuple and cell information in the term payload. -->
				<filter class="org.sindice.siren.solr.analysis.SirenPayloadFilterFactory"/>
        
      </analyzer>

			<analyzer type="query" class="org.sindice.siren.solr.analysis.MultiQueryAnalyzerWrapper"/>
			
    </fieldType>
		
    <!--
      The SIREn Tabular field type: the index analyzer is the same than for 
			ntriple. The only changes is in the query analyzer.

      Field norms are not useful for SIREn fields. Set omitNorms to true reduces
      memory consumption, and improve ranking.
    -->
    <fieldType name="tabular" class="solr.TextField" omitNorms="true">
      <analyzer type="index">
        <tokenizer class="org.sindice.siren.solr.analysis.TupleTokenizerFactory"
				           subschema="ntriple-schema.xml"
                   literal-fieldtype="ntriple-literal"/>
        <filter class="org.sindice.siren.solr.analysis.TokenTypeFilterFactory"/>
        <filter class="solr.StandardFilterFactory"/>
        <filter class="org.sindice.siren.solr.analysis.URILocalnameFilterFactory"/> 
        <filter class="org.sindice.siren.solr.analysis.URITrailingSlashFilterFactory"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.StopFilterFactory"
                ignoreCase="true"
                words="stopwords.txt"
                enablePositionIncrements="true"
                />
        <filter class="solr.LengthFilterFactory" min="2" max="256"/>
        <filter class="org.sindice.siren.solr.analysis.SirenPayloadFilterFactory"/>
        
      </analyzer>
      <!-- TODO: Entity query analyzer
      <analyzer type="query">
        <tokenizer class="org.sindice.siren.solr.analysis.EntityQueryTokenizerFactory"/>
      </analyzer>
			-->
    </fieldType>
    
 </types>


 <fields>

	 	<!-- The ID (URL) of the document 
		     Use the 'string' field type (no tokenisation)
		-->
   	<field name="id" type="string" indexed="true" stored="true" required="true"/>
   
	 	<!-- The URL of the document 
		     Use the 'text' field type in order to be tokenised
		-->
   	<field name="url" type="text" indexed="true" stored="true" required="true"/>
		
		<!-- n-triple indexing scheme -->
   	<field name="ntriple" type="ntriple" indexed="true" stored="false" multiValued="false"/>
		
		<!-- tabular indexing scheme -->
    <field name="tabular" type="tabular" indexed="true" stored="false" multiValued="false"/>

 </fields>

 <!-- Field to use to determine and enforce document uniqueness. 
      Unless this field is marked with required="false", it will be a required field
   -->
 <uniqueKey>id</uniqueKey>

 <!-- field for the QueryParser to use when an explicit fieldname is absent -->
 <defaultSearchField>ntriple</defaultSearchField>

 <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
 <solrQueryParser defaultOperator="AND"/>

 <!-- copyField commands copy one field to another at the time a document
      is added to the index.  It's used either to index the same field differently,
      or to add multiple fields to the same field for easier/faster searching.  -->

 <copyField source="url" dest="id"/>

</schema>
